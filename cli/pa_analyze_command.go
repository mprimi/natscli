package cli

import (
	"errors"
	"fmt"
	"math"

	"github.com/choria-io/fisk"
	"github.com/mprimi/natscli/archive"
	"github.com/nats-io/nats-server/v2/server"
)

const (
	clusterMemoryUsageThresholdPercentage = 0.6
)

type PaAnalyzeCmd struct {
	archivePath string
}

type checkFunc func(r *archive.Reader) error

var checks = []checkFunc{
	checkServerVersions,
	checkSlowConsumers,
	checkClusterMemoryUsage,
	checkStreamConsistency,
}

func configurePaAnalyzeCommand(srv *fisk.CmdClause) {
	c := &PaAnalyzeCmd{}

	analyze := srv.Command("analyze", "analyze and check for issues based on archive generated by the `gather` subcmd").Action(c.analyze)
	analyze.Arg("archivePath", "path of archive to extract information from and analyze").Required().StringVar(&c.archivePath)
}

func (c *PaAnalyzeCmd) analyze(_ *fisk.ParseContext) error {
	ar, err := archive.NewReader(c.archivePath)
	if err != nil {
		return err
	}
	defer ar.Close()

	for _, checkFunc := range checks {
		err := checkFunc(ar)
		if err != nil {
			return err
		}
	}

	return nil
}

func checkServerVersions(r *archive.Reader) error {
	var (
		serverTags     = r.ListServerTags()
		serverVersions = make(map[string][]string, len(serverTags))
	)

	for _, serverTag := range serverTags {
		serverVarz := server.Varz{}
		r.Load(&serverVarz, &serverTag, archive.TagServerVars())
		_, exists := serverVersions[serverVarz.Version]
		if !exists {
			serverVersions[serverVarz.Version] = []string{}
		}
		serverVersions[serverVarz.Version] = append(serverVersions[serverVarz.Version], serverTag.Value)
	}

	if len(serverVersions) == 1 {
		fmt.Println("✅ All servers are running the same version")
	} else {
		fmt.Println("🔔 Warning: Servers are running different versions")
		fmt.Println("--- SERVER VERSIONS ---")
		for version, servers := range serverVersions {
			fmt.Printf("%s: %v servers\n", version, servers)
		}
	}

	return nil
}

func checkSlowConsumers(r *archive.Reader) error {
	serverTags := r.ListServerTags()
	for _, serverTag := range serverTags {
		serverVarz := server.Varz{}
		r.Load(&serverVarz, &serverTag, archive.TagServerVars())
		if serverVarz.SlowConsumers > 0 {
			fmt.Printf("🔔 Warning: %v slow consumers on server %v\n", serverVarz.SlowConsumers, serverTag.Value)
		}
	}
	fmt.Println("✅ No slow consumers found")
	return nil
}

func checkClusterMemoryUsage(r *archive.Reader) error {
	allGood := true
	serverTags := r.ListServerTags()
	for _, clusterTag := range r.ListClusterTags() {
		cluster := clusterTag.Value
		clusterMemoryUsage := make(map[string]float64, len(serverTags))
		for _, serverTag := range serverTags {
			serverVarz := server.Varz{}
			r.Load(&serverVarz, &serverTag, archive.TagServerVars())
			clusterMemoryUsage[serverTag.Value] = float64(serverVarz.Mem)
		}

		average := func(m map[string]float64) float64 {

			var (
				median float64
				count  int
			)

			for _, v := range m {
				median += v
				count++
			}

			return median / float64(count)
		}

		medianMem := average(clusterMemoryUsage)
		medianMemMb := medianMem / 1024 / 1024
		for server, mem := range clusterMemoryUsage {
			if math.Abs(mem-medianMem)/medianMem > clusterMemoryUsageThresholdPercentage {
				allGood = false
				memMb := mem / 1024 / 1024
				fmt.Printf("🔔 server: %v memory usage (%.2fMb) exceeds cluster: %s median memory usage (%.2fMb) by over %.2f%% threshold\n", server, memMb, cluster, medianMemMb, clusterMemoryUsageThresholdPercentage*100)
			}
		}
	}
	if allGood {
		fmt.Println("✅ Cluster memory usage for all servers is within threshold")
	}

	return nil
}

func checkStreamConsistency(r *archive.Reader) error {
	type streamConsistencyData struct {
		stream      string
		serverId    string
		numMessages uint64
		bytes       uint64
		leader      string
		replicas    []*server.PeerInfo
	}

	var streamsConsistent = true

	for _, accountTag := range r.ListAccountTags() {
		for _, streamTag := range r.ListStreamTags() {
			for _, clusterTag := range r.ListClusterTags() {
				streams := make(map[string]streamConsistencyData)
				for _, serverTag := range r.ListServerTags() {
					streamDetail := server.StreamDetail{}
					if err := r.Load(&streamDetail, &accountTag, &serverTag, &streamTag, &clusterTag); err != nil {
						if errors.Is(err, archive.ErrNoMatches) {
							continue
						}
						return err
					}
					streams[serverTag.Value] = streamConsistencyData{
						stream:      streamDetail.Name,
						serverId:    serverTag.Value,
						numMessages: streamDetail.State.Msgs,
						bytes:       streamDetail.State.Bytes,
						leader:      streamDetail.Cluster.Leader,
						replicas:    streamDetail.Cluster.Replicas,
					}
				}

				var (
					bytes  uint64
					leader string
				)

				// check if all replicas are current
				for _, stream := range streams {
					for _, replica := range stream.replicas {
						if !replica.Current {
							fmt.Printf("🔔 Warning: replica %v is not current for stream %v\n", replica.Name, stream.stream)
							streamsConsistent = false
						}
					}
				}

				// check if all streams have the same bytes
				// TODO: add tolerances
				for _, stream := range streams {
					if bytes == 0 {
						bytes = stream.bytes
					}
					if bytes != stream.bytes {
						fmt.Printf("🔔 Warning: stream: %v has different bytes across servers\n", stream.stream)
						for _, stream := range streams {
							fmt.Printf("server: %v, bytes: %v\n", stream.serverId, stream.bytes)
						}
						streamsConsistent = false
						break
					}
				}
				// check if leader is consistent
				for _, stream := range streams {
					if leader == "" {
						leader = stream.leader
					}
					if leader != stream.leader {
						fmt.Printf("🔔 Warning: stream: %v has different leaders across servers\n", stream.stream)
						for _, stream := range streams {
							fmt.Printf("server: %v, leader: %v\n", stream.serverId, stream.leader)
						}
						streamsConsistent = false
						break
					}
				}
			}
		}
	}

	if streamsConsistent {
		fmt.Println("✅ All streams are consistent across all replicas")
	} else {
		fmt.Println("❌ Warning: Streams are not consistent across all replicas")
	}
	return nil
}
