// Copyright 2024 The NATS Authors
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cli

import (
	"errors"
	"fmt"
	"math"

	"github.com/choria-io/fisk"
	"github.com/mprimi/natscli/archive"
	"github.com/nats-io/nats-server/v2/server"
)

type paAnalyzeCmd struct {
	archivePath   string
	veryVerbose   bool
	examplesLimit uint
	allExamples   bool
}
type checkStatus int

func (s checkStatus) badge() string {
	switch s {
	case Pass:
		return "âœ… PASS"
	case Fail:
		return "âŒ FAIL"
	case SomeIssues:
		return "âš ï¸ WARN"
	case Skipped:
		return "â—»ï¸ SKIP"
	default:
		panic(s)
	}
}

const (
	Skipped checkStatus = iota
	Pass    checkStatus = iota
	Fail
	SomeIssues
)

func configurePaAnalyzeCommand(srv *fisk.CmdClause) {
	c := &paAnalyzeCmd{}

	analyze := srv.Command("analyze", "perform checks against an archive generated by the Gather subcommand").Action(c.analyze)
	analyze.Arg("archive-path", "path to input archive to analyze").Required().StringVar(&c.archivePath)
	analyze.Flag("examples", "Maximum number of example issues to display per check").Default("5").UintVar(&c.examplesLimit)
	analyze.Flag("all-examples", "Display all issues detected by each check").UnNegatableBoolVar(&c.allExamples)
	// Hidden flags
	analyze.Flag("very-verbose", "Print a lot of intermediate detailed during analysis").Hidden().BoolVar(&c.veryVerbose)

}

func (cmd *paAnalyzeCmd) analyze(_ *fisk.ParseContext) error {
	// Configure based on options
	if cmd.allExamples {
		cmd.examplesLimit = 0
	}

	// Open archive
	ar, err := archive.NewReader(cmd.archivePath)
	if err != nil {
		return err
	}
	defer func() {
		err := ar.Close()
		if err != nil {
			fmt.Printf("Failed to close archive reader: %s\n", err)
		}
	}()

	// List of known checks
	var checks = []struct {
		checkName string
		checkFunc func(r *archive.Reader) (checkStatus, error)
	}{
		{
			"Server health",
			cmd.checkServerHealth,
		},
		{
			"Uniform server version",
			cmd.checkServerVersions,
		},
		{
			"Slow consumers",
			cmd.checkSlowConsumers,
		},
		{
			"Memory usage",
			cmd.checkClusterMemoryUsageOutliers,
		},
		{
			"Lagging stream replicas",
			cmd.checkLaggingStreamReplicas,
		},
	}

	// Run checks, one at the time
	checkOutcomes := make([]checkStatus, len(checks))
	for i, check := range checks {

		fmt.Printf("\n--\n")
		cmd.logDebug("Running check: %s", check.checkName)
		outcome, err := check.checkFunc(ar)
		if err != nil {
			return fmt.Errorf("check '%s' error: %w", check.checkName, err)
		}
		checkOutcomes[i] = outcome

		fmt.Printf("%s - %s\n--\n", outcome.badge(), check.checkName)
	}

	return nil
}

// checkServerVersions ensures all servers discovered are running the same version
func (cmd *paAnalyzeCmd) checkServerVersions(r *archive.Reader) (checkStatus, error) {
	var (
		serverTags           = r.ListServerTags()
		versionsToServersMap = make(map[string][]string)
		versionsList         = make([]string, 0)
	)

	examples := newCollectionOfExamples(cmd.examplesLimit)

	artifactType := archive.TagServerVars()
	outcome := Pass

	for _, serverTag := range serverTags {
		serverName := serverTag.Value
		var serverVarz server.Varz

		err := r.Load(&serverVarz, &serverTag, artifactType)
		if errors.Is(err, archive.ErrNoMatches) {
			cmd.logWarning("Artifact 'VARZ' is missing for server %s", serverName)
			continue
		} else if err != nil {
			return Skipped, fmt.Errorf("failed to load variables for server %s: %w", serverTag.Value, err)
		}

		version := serverVarz.Version

		_, exists := versionsToServersMap[version]
		if !exists {
			versionsToServersMap[version] = []string{}
			versionsList = append(versionsList, version)
			examples.Addf("%s - %s", serverName, version)
		}
		versionsToServersMap[version] = append(versionsToServersMap[version], serverName)
	}

	if len(versionsList) == 1 {
		cmd.logInfo("All servers are running version %s", versionsList[0])
	} else {
		cmd.logIssue("Servers are running %d different versions", len(versionsList))
		cmd.logExamples(examples)
	}

	return outcome, nil
}

func (cmd *paAnalyzeCmd) checkServerHealth(r *archive.Reader) (checkStatus, error) {
	serverTags := r.ListServerTags()
	artifactType := archive.TagHealth()
	notHealthy, healthy := 0, 0
	examples := newCollectionOfExamples(cmd.examplesLimit)

	for _, serverTag := range serverTags {
		serverName := serverTag.Value
		var health server.HealthStatus

		err := r.Load(&health, &serverTag, artifactType)
		if errors.Is(err, archive.ErrNoMatches) {
			cmd.logWarning("Artifact 'HEALTHZ' is missing for server %s", serverName)
			continue
		} else if err != nil {
			return Skipped, fmt.Errorf("failed to load health for server %s: %w", serverName, err)
		}

		if health.Status != "ok" {
			examples.Addf("%s: %d - %s", serverName, health.StatusCode, health.Status)
			notHealthy += 1
		} else {
			healthy += 1
		}
	}

	if notHealthy > 0 {
		cmd.logIssue("%d/%d servers are not healthy", notHealthy, healthy+notHealthy)
		cmd.logExamples(examples)
		return SomeIssues, nil
	}

	cmd.logInfo("%d/%d servers are healthy", healthy, healthy)
	return Pass, nil
}

// checkSlowConsumers alerts for any slow consumer found on any server
func (cmd *paAnalyzeCmd) checkSlowConsumers(r *archive.Reader) (checkStatus, error) {
	serverTags := r.ListServerTags()
	totalSlowConsumers := int64(0)
	serversWithSlowConsumers := make(map[string]int64)
	examples := newCollectionOfExamples(cmd.examplesLimit)

	for _, serverTag := range serverTags {
		serverName := serverTag.Value
		var serverVarz server.Varz
		err := r.Load(&serverVarz, &serverTag, archive.TagServerVars())
		if err != nil {
			return Skipped, fmt.Errorf("failed to load Varz for server %s: %w", serverName, err)
		}

		if slowConsumers := serverVarz.SlowConsumers; slowConsumers > 0 {
			serversWithSlowConsumers[serverName] = slowConsumers
			examples.Addf("%s: %d slow consumers", serverName, slowConsumers)
			totalSlowConsumers += slowConsumers
		}
	}

	if totalSlowConsumers > 0 {
		cmd.logIssue("Total slow consumers: %d over %d servers", totalSlowConsumers, len(serversWithSlowConsumers))
		cmd.logExamples(examples)
		return SomeIssues, nil
	}
	return Pass, nil
}

const checkClusterMemoryUsageOutlierThreshold = 0.5 // Warn if one node is using over 1.5x the average
// checkClusterMemoryUsageOutliers iterates over clusters and checks whether any of the server memory usage is
// significantly higher than the cluster average.
func (cmd *paAnalyzeCmd) checkClusterMemoryUsageOutliers(r *archive.Reader) (checkStatus, error) {
	typeTag := archive.TagServerVars()
	clusterNames := r.GetClusterNames()
	examples := newCollectionOfExamples(cmd.examplesLimit)

	clustersWithIssuesMap := make(map[string]interface{}, len(clusterNames))

	for _, clusterName := range clusterNames {
		clusterTag := archive.TagCluster(clusterName)

		serverNames := r.GetClusterServerNames(clusterName)
		clusterMemoryUsageMap := make(map[string]float64, len(serverNames))
		clusterMemoryUsageTotal := float64(0)
		numServers := 0 // cannot use len(serverNames) as some artifacts may be missing

		for _, serverName := range serverNames {
			serverTag := archive.TagServer(serverName)

			var serverVarz server.Varz
			err := r.Load(&serverVarz, clusterTag, serverTag, typeTag)
			if errors.Is(err, archive.ErrNoMatches) {
				cmd.logWarning("Artifact 'VARZ' is missing for server %s in cluster %s", serverName, clusterName)
				continue
			} else if err != nil {
				return Skipped, fmt.Errorf("failed to load VARZ for server %s in cluster %s: %w", serverName, clusterName, err)
			}

			numServers += 1
			clusterMemoryUsageMap[serverTag.Value] = float64(serverVarz.Mem)
			clusterMemoryUsageTotal += float64(serverVarz.Mem)
		}

		clusterMemoryUsageMean := clusterMemoryUsageTotal / float64(numServers)
		threshold := clusterMemoryUsageMean + (clusterMemoryUsageMean * checkClusterMemoryUsageOutlierThreshold)

		for serverName, serverMemoryUsage := range clusterMemoryUsageMap {
			if serverMemoryUsage > threshold {
				examples.Addf(
					"Cluster %s avg: %s, server %s: %s",
					clusterName,
					fiBytes(uint64(clusterMemoryUsageMean)),
					serverName,
					fiBytes(uint64(serverMemoryUsage)),
				)
				clustersWithIssuesMap[clusterName] = nil
			}
		}
	}

	if len(clustersWithIssuesMap) > 0 {
		cmd.logIssue(
			"Servers with memory usage %.0f%% above cluster average: %d in %d clusters",
			checkClusterMemoryUsageOutlierThreshold*100,
			examples.Count(),
			len(clustersWithIssuesMap),
		)
		cmd.logExamples(examples)
		return SomeIssues, nil
	}
	return Pass, nil
}

const checkLaggingStreamReplicasThreshold = 0.1 // Warn if a replica is 10% behind the maximum in group
// checkLaggingStreamReplicas inspects all streams and checks that no replica is behind (lastSeq) compared to the
// replica with the highest lastSeq
func (cmd *paAnalyzeCmd) checkLaggingStreamReplicas(r *archive.Reader) (checkStatus, error) {
	typeTag := archive.TagStreamDetails()
	accountNames := r.GetAccountNames()
	examples := newCollectionOfExamples(cmd.examplesLimit)

	if len(accountNames) == 0 {
		cmd.logInfo("No accounts found in archive")
	}

	accountsWithStreams := make(map[string]interface{})
	streamsInspected := make(map[string]interface{})
	laggingReplicas := 0

	for _, accountName := range accountNames {
		accountTag := archive.TagAccount(accountName)
		streamNames := r.GetAccountStreamNames(accountName)

		if len(streamNames) == 0 {
			cmd.logDebug("No streams found in account: %s", accountName)
		}

		for _, streamName := range streamNames {

			// Track accounts with at least one streams
			accountsWithStreams[accountName] = nil

			streamTag := archive.TagStream(streamName)
			serverNames := r.GetStreamServerNames(accountName, streamName)

			cmd.logDebug(
				"Inspecting account '%s' stream '%s', found %d servers: %v",
				accountName,
				streamName,
				len(serverNames),
				serverNames,
			)

			// Create map server->streamDetails
			replicasStreamDetails := make(map[string]*server.StreamDetail, len(serverNames))
			streamIsEmpty := true

			for _, serverName := range serverNames {
				serverTag := archive.TagServer(serverName)
				streamDetails := &server.StreamDetail{}
				err := r.Load(streamDetails, accountTag, streamTag, serverTag, typeTag)
				if errors.Is(err, archive.ErrNoMatches) {
					cmd.logWarning(
						"Artifact not found: %s for stream %s in account %s by server %s",
						typeTag.Value,
						streamName,
						accountName,
						serverName,
					)
					continue
				} else if err != nil {
					return Skipped, fmt.Errorf("failed to lookup stream artifact: %w", err)
				}

				if streamDetails.State.LastSeq > 0 {
					streamIsEmpty = false
				}

				replicasStreamDetails[serverName] = streamDetails
				// Track streams with least one artifact
				streamsInspected[accountName+"/"+streamName] = nil
			}

			// Check that all replicas are not too far behind the replica with the highest message & byte count
			if !streamIsEmpty {
				// Find the highest lastSeq
				highestLastSeq, highestLastSeqServer := uint64(0), ""
				for serverName, streamDetail := range replicasStreamDetails {
					lastSeq := streamDetail.State.LastSeq
					if lastSeq > highestLastSeq {
						highestLastSeq = lastSeq
						highestLastSeqServer = serverName
					}
				}
				cmd.logDebug(
					"Stream %s / %s highest last sequence: %d @ %s",
					accountName,
					streamName,
					highestLastSeq,
					highestLastSeqServer,
				)

				// Check if some server's sequence is below warning threshold
				lastSequenceThreshold := uint64(math.Max(0, float64(highestLastSeq)-(float64(highestLastSeq)*checkLaggingStreamReplicasThreshold)))
				for serverName, streamDetail := range replicasStreamDetails {
					lastSeq := streamDetail.State.LastSeq
					if lastSeq < lastSequenceThreshold {
						examples.Addf(
							"%s/%s server %s lastSequence: %d is behind highest lastSequence: %d on server: %s",
							accountName,
							streamName,
							serverName,
							lastSeq,
							highestLastSeq,
							highestLastSeqServer,
						)
						laggingReplicas += 1
					}
				}
			}
		}
	}

	cmd.logInfo("Inspected %d streams across %d accounts", len(streamsInspected), len(accountsWithStreams))

	if laggingReplicas > 0 {
		cmd.logIssue("Found %d replicas lagging behind", laggingReplicas)
		cmd.logExamples(examples)
		return SomeIssues, nil
	}
	return Pass, nil
}

// logSevereIssue for serious problems that need to be addressed
func (cmd *paAnalyzeCmd) logSevereIssue(format string, a ...any) {
	fmt.Printf("â€¼ï¸  "+format+"\n", a...)
}

// logIssue for issues that need attention that need to be addressed
func (cmd *paAnalyzeCmd) logIssue(format string, a ...any) {
	fmt.Printf("â—ï¸ "+format+"\n", a...)
}

// logInfo for neutral and positive messages
func (cmd *paAnalyzeCmd) logInfo(format string, a ...any) {
	fmt.Printf("â„¹ï¸  "+format+"\n", a...)
}

// logWarning for issues running the check itself, but not serious enough to terminate with an error
func (cmd *paAnalyzeCmd) logWarning(format string, a ...any) {
	fmt.Printf("âš ï¸  "+format+"\n", a...)
}

// logDebug for very fine grained progress, disabled by default
func (cmd *paAnalyzeCmd) logDebug(format string, a ...any) {
	if cmd.veryVerbose {
		fmt.Printf("ðŸ”¬  "+format+"\n", a...)
	}
}

// logExamples for printing some examples without risking flooding the output
func (cmd *paAnalyzeCmd) logExamples(examples *examplesCollection) {
	if len(examples.examples) > 0 {
		for _, example := range examples.examples {
			fmt.Printf("   - " + example + "\n")
		}
		if examples.dropped > 0 {
			fmt.Printf("   - ...%d more...\n", examples.dropped)
		}
	}
}

type examplesCollection struct {
	examples []string
	limit    int
	dropped  int
}

func (e *examplesCollection) Addf(format string, a ...any) {
	if len(e.examples) < e.limit {
		e.examples = append(e.examples, fmt.Sprintf(format, a...))
	} else {
		e.dropped += 1
	}
}

func (e *examplesCollection) Count() int {
	return e.dropped + len(e.examples)
}

func newCollectionOfExamples(limit uint) *examplesCollection {
	if limit == 0 {
		// If set to unlimited, set a very large limit
		limit = 1024
	}

	return &examplesCollection{
		examples: make([]string, 0, limit),
		limit:    int(limit),
		dropped:  0,
	}
}
